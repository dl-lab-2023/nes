# TODOS

### Task 1
- [X] create new module to work in
  - nes/nasbench201/scripts/run_hp_search.py
- [ ] find a base architecture from the paper
  - where to download?
  - reset parameters -> only keep architecture
- [ ] create hyperparameter-space
  - what hyperparameters were used to train the architecture originally?
  - first step: LearningRate & Optimizer
- [ ] sample hyperparameter-space
  - sample randomly
  - how to sample logarithmic hp such as learning-rate?
- [ ] train models
  - run on cluster?
  - save results?
- [ ] evaluate
  - plots?