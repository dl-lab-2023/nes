# TODOS

### Task 1
- [X] create new module to work in
  - nes/nasbench201/scripts/run_hp_search.py
- [X] find a base architecture from the paper
  - where to download?
  - reset parameters -> only keep architecture
- [X] create hyperparameter-space
  - what hyperparameters were used to train the architecture originally?
  - first step: LearningRate & Optimizer
- [X] sample hyperparameter-space
  - sample randomly
  - how to sample logarithmic hp such as learning-rate?
- [X] train models
  - run on cluster?
  - save results?
- [ ] evaluate
  - plots?